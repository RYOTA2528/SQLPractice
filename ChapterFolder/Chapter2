
(代表的なビッグデータの処理ツール)																									
①PostgreSQL																									
・オープンソースのRDBです。標準SQLへの準拠率が高い。ウィンドウ関数やCTEなど、分析に必須となる関数が多く収容されてる。																									
・特有の拡張機能が多く実装されてる。																									
・小規模な分析やSQL学習を目的とする利用に最適。ローカルで比較的軽量で動作するPostgreSQLの使用がおすすめ

②Apache Hive																									
・HDFSと呼ばれる分散ファイルシステム上のデータを、SQLライクなインターフェースで簡単に処理できる																									
・バラバラに配置されたデータを並列に処理する手法はMapReduce																									
・HDFSとMapReduceのアーキテクチャを実装したシステムが初期のApache Hadoop、HiveはHadoopエコシステムの一部																									
・（デメリット）	
　           　・PostgreSQLと比較するとあくまでファイルベースのシステムある。特定レコードだけの更新・削除は難しく、インデックスも基本的には存在しない。クエリ発行時にファイル全件を走査することになる。																								
	             ・あくまでもスループットを高めるためのものであるためレイテンシの低い処理を求められるケースにむいてない。																								
・（メリット）
               ・クエリ実行時に動的にデータの定義を与えられる。(ex)『Japan Tokyo Minato-ku』のデータに対して、『国・都道府県・市区町村』の3つのカラムデータとして取り扱うのではでなく、1つのとして扱うことが可能です。これにより『具体的に何に使うかわからないがとりあえず保存しておきたいデータ』をHDFS上に蓄積し、必要になったタイミングに応じて、動的にスキーマに定義できる																								
	             ・データ分析のための豊富なUDFを活用でき、SQLだけでは実現が難しい文字列処理なども簡単に実現できる。→Javaで実装可能！	
	
③Amazon Redshift	　																								
・AWSで提供される並列RDS																									
・行単位での更新・削除も可能。																									
（メリット）	・RDBでは扱えない大量データに対して、インタラクティブにクエリを発行したい場合に効果的。HiveではMapReduceによる分散処理を実行する場合、どんな軽いジョブでも10秒以上かかる。Redshiftでは最短数ミリ秒で実行可能。																								
	　　　　　　・利用時間に応じて課金される。																								
（デメリット）	
　　　　　　　・パフォーマンスチューニングや金額を抑えたい運用を行いたい場合、最適なノード数やノードスペックの見積もり、インスタンスの起動・終了の管理などが必要となりある程度の専門的な知識が必要となる。																								
	            ・PostgreSQLとのアーキテクチャ的な違いとして、Redshiftは列指向のストレージ（レコードごとではなく列ごとに保存）である点が特徴的であり、テーブル設計やクエリ実行時に通常のRDBとは異なる発想も必要になる。																								
	            ・このアーキテクチャによりデータ圧縮率を向上させたり、クエリ実行時にディスクI/Oを削除できます。																								
              ・分析に必要なデータを全て一つのテーブル列に追加する形式をとるケースも多々あり、クエリ実行の際『SELECT*』などの全ての列を取得するクエリはパフォーマンスを低下させることにつながるため
  　             必ず、『必要な列に絞って』クエリ実行する必要がある。
  　
④Google BigQuery
・ビッグデータ解析のためのGoogle上のクラウドサービス。
・SQLライクなクエリ言語。主に使用するのが『スタンダードSQL』で、CTEや相関サブクエリに対応するなど、一般的な構文でクエリを記述可能となっています。
（メリット）・Redshiftと違い、自分で計算ノードのインスタンスを管理する必要がなく、利用時間ではなく読み込むだデータ量で課金される点が特徴的。
　　　　　　・有料版GoogleAnlticsのデータをBigQueryで取り扱い可能であり、Google Cloud Storagesから手軽にデータをロードできるなど、他のサービスとの親和性が高い。
(デメリット)
　　　　　　・読み込んだデータ量で課金される
　　　　　　・データをロードする必要がある場合には、データ量に応じた金額が発生するため、クエリ発行時のデータを抑えるため、一緒に読み込まれやすいデータの範囲ごとに
　　　　　　　テーブルを分割する、必要なカラムだけ選択してSELECTするなどテクニカルが必要。
　　　　　　・列指向のアーキテクチャです。
　　　　　　
⑤SparkSQL
・MapReduceに続く分散処理フレームワークであるApacha Sparkの機能の内、SQLインターフェースをに関連する機能を表す言葉。
・オープンソースのフレームワークである為、無料で利用できる。非常に速い。機械学習やグラフ処理、リアルタイムストリーミング処理など、さまざまな処理を手軽に分散処理できる機能を提供。
（メリット）
						・ビッグデータ活用に関連するほとんどの処理をオールインワンで実現できる。
						・SparkはインターフェースとしてSQLだけでなく、PythonやScala、Java、Rなどのプログラミング言語に対応。データのインポートやエクスポート機能も豊富にジッソyされてる。
						・DataFramesのAPIが標準であり、どの言語を用いても自動的に最適化される。
						・DataFramesのAPIはSQLに似た宣言的な構文でデータを操作できるだけでなく、手続き型のプログラミングに近い方法でプログラムを実装できる。
						　(ex)例えば、中間データを逐一標準出力に書き出して、途中経過を確認しながら処理を実行できたり、データ処理を細かいモジュールに分割して単体テストやアノテーション
						　　　を実装できるメリットに加え、機械学習や統計処理、グラフ処理などSQLだけでは難しい処理を統合したりリアルタイムに受け取ったデータをストリーム処理するなど多種多様なメリットがある。

【データについて】
（注意）
・業務前にどんな種類のデータを持ち合わせるかを把握することで、可能なことと不可能なことの見当がつくため、手戻りなくスムーズに業務を進められる。
（データの種類）
『業務データ』と『ログデータ』について
		『業務データ』
		→サービス・システムを運用する目的で構築されたデータベースに存在するデータ
		→ほとんどが『更新型』のデータ(ex)商品データの更新
		→連続したデータの途中で何らかの不具合が生じてもロールバック処理をし、処理を取り消せる。正常に処理できたものが保存される仕組みを持つ（トランザクション機能）、その為
		、正確な値であることが求められる。(ex)売り上げに関するレポートはこの業務レポートが使われる。
		→データの冗長性を控除し、データの整合性を保ちやすいようデータを保存する（正規化）。その為、1つのテーブルをさんしょうするだけではそのデータが誰の行動かなんの購入かまでは把握できない。
		　ER図に書き起こしたうえでデータの整合性を保ちやすいよう正規化する。複数のテーブルの結合が大切
				業務データは2種類
					『トランザクションデータ』
					(ex)購入データ・口コミデータ・ゲームのプレイデータなど。サービス・システムを通じてユーザーの行動を記録したデータを示す。データの日付・時刻・マスターデータの怪異ID,
					　　商品ID、数量、価格帯等が含まれることが多い。
					　　これらのデータは会員IDと商品IDで格納されてるケースが多く、会員の性別や居住地、商品のカテゴリなどをレポートにして扱うことはできない。
				　『マスターデータ』
				　(ex)都道府県データ、カテゴリデータ、商品マスタなど、サービス・システムが定義するデータをマスターデータと呼ぶ。会員に関する情報も会員マスタデータに分類されてる。
				　
				　つまり、トランザクションデータの商品IDとマスターデータを突き合わせることで、商品名や商品カテゴリーを、販売日などが明らかになりレポート業務の幅が広がる。
				　【注意】：トランザクションデータのみでは、分析範囲が限定される。含まれるマスターデータはレポート業務の前に一通り、そろってることを確認すること！！
				　
		『ログデータ』
			→集計・分析を主な用途とした設計されてるデータ
			→サイトに特定のタグを埋め込んで送信するデータ
			→特定の行動に対して、サーバ側で出力するデータ
					これらは『追記型データ』です。
											：(ex)価格が変更されたり、ユーザー情報が更新されてもすでに出力したデータが書き換えられることはない。
				　